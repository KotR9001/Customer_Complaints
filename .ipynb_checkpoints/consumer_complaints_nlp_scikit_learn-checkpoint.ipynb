{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Latest Version of Spark\n",
    "#%pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3 \n",
    "\n",
    " \n",
    "\n",
    "# \n",
    "\n",
    "# Licensed to the Apache Software Foundation (ASF) under one or more \n",
    "\n",
    "# contributor license agreements.  See the NOTICE file distributed with \n",
    "\n",
    "# this work for additional information regarding copyright ownership. \n",
    "\n",
    "# The ASF licenses this file to You under the Apache License, Version 2.0 \n",
    "\n",
    "# (the \"License\"); you may not use this file except in compliance with \n",
    "\n",
    "# the License.  You may obtain a copy of the License at \n",
    "\n",
    "# \n",
    "\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0 \n",
    "\n",
    "# \n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software \n",
    "\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS, \n",
    "\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "\n",
    "# See the License for the specific language governing permissions and \n",
    "\n",
    "# limitations under the License. \n",
    "\n",
    "# \n",
    "\n",
    " \n",
    "\n",
    "# This script attempt to determine the correct setting for SPARK_HOME given \n",
    "\n",
    "# that Spark may have been installed on the system with pip. \n",
    "\n",
    " \n",
    "\n",
    "import os \n",
    "\n",
    "import sys \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "def _find_spark_home(): \n",
    "\n",
    "    \"\"\"Find the SPARK_HOME.\"\"\" \n",
    "\n",
    "    # If the environment has SPARK_HOME set trust it. \n",
    "\n",
    "    if \"SPARK_HOME\" in os.environ: \n",
    "\n",
    "        return os.environ[\"SPARK_HOME\"] \n",
    "\n",
    " \n",
    "\n",
    "    def is_spark_home(path): \n",
    "\n",
    "        \"\"\"Takes a path and returns true if the provided path could be a reasonable SPARK_HOME\"\"\" \n",
    "\n",
    "        return (os.path.isfile(os.path.join(path, \"bin/spark-submit\")) and \n",
    "\n",
    "                (os.path.isdir(os.path.join(path, \"jars\")) or \n",
    "\n",
    "                 os.path.isdir(os.path.join(path, \"assembly\")))) \n",
    "\n",
    " \n",
    "\n",
    "    # Spark distribution can be downloaded when PYSPARK_HADOOP_VERSION environment variable is set. \n",
    "\n",
    "    # We should look up this directory first, see also SPARK-32017. \n",
    "\n",
    "    spark_dist_dir = \"spark-distribution\" \n",
    "\n",
    "    paths = [ \n",
    "\n",
    "        \"../\",  # When we're in spark/python. \n",
    "\n",
    "        # Two case belows are valid when the current script is called as a library. \n",
    "\n",
    "        os.path.join(os.path.dirname(os.path.realpath('spark-3.3.2-bin-hadoop3.tgz')), spark_dist_dir), \n",
    "\n",
    "        os.path.dirname(os.path.realpath('spark-3.3.2-bin-hadoop3.tgz'))] \n",
    "\n",
    " \n",
    "\n",
    "    # Add the path of the PySpark module if it exists \n",
    "\n",
    "    import_error_raised = False \n",
    "\n",
    "    from importlib.util import find_spec \n",
    "\n",
    "    try: \n",
    "\n",
    "        module_home = os.path.dirname(find_spec(\"pyspark\").origin) \n",
    "\n",
    "        paths.append(os.path.join(module_home, spark_dist_dir)) \n",
    "\n",
    "        paths.append(module_home) \n",
    "\n",
    "        # If we are installed in edit mode also look two dirs up \n",
    "\n",
    "        # Downloading different versions are not supported in edit mode. \n",
    "\n",
    "        paths.append(os.path.join(module_home, \"../../\")) \n",
    "\n",
    "    except ImportError: \n",
    "\n",
    "        # Not pip installed no worries \n",
    "\n",
    "        import_error_raised = True \n",
    "\n",
    " \n",
    "\n",
    "    # Normalize the paths \n",
    "\n",
    "    paths = [os.path.abspath(p) for p in paths] \n",
    "\n",
    " \n",
    "\n",
    "    try: \n",
    "\n",
    "        return next(path for path in paths if is_spark_home(path)) \n",
    "\n",
    "    except StopIteration: \n",
    "\n",
    "        print(\"Could not find valid SPARK_HOME while searching {0}\".format(paths), file=sys.stderr) \n",
    "\n",
    "        if import_error_raised: \n",
    "\n",
    "            print( \n",
    "\n",
    "                \"\\nDid you install PySpark via a package manager such as pip or Conda? If so,\\n\" \n",
    "\n",
    "                \"PySpark was not found in your Python environment. It is possible your\\n\" \n",
    "\n",
    "                \"Python environment does not properly bind with your package manager.\\n\" \n",
    "\n",
    "                \"\\nPlease check your default 'python' and if you set PYSPARK_PYTHON and/or\\n\" \n",
    "\n",
    "                \"PYSPARK_DRIVER_PYTHON environment variables, and see if you can import\\n\" \n",
    "\n",
    "                \"PySpark, for example, 'python -c 'import pyspark'.\\n\" \n",
    "\n",
    "                \"\\nIf you cannot import, you can install by using the Python executable directly,\\n\" \n",
    "\n",
    "                \"for example, 'python -m pip install pyspark [--user]'. Otherwise, you can also\\n\" \n",
    "\n",
    "                \"explicitly set the Python executable, that has PySpark installed, to\\n\" \n",
    "\n",
    "                \"PYSPARK_PYTHON or PYSPARK_DRIVER_PYTHON environment variables, for example,\\n\" \n",
    "\n",
    "                \"'PYSPARK_PYTHON=python3 pyspark'.\\n\", file=sys.stderr) \n",
    "\n",
    "        sys.exit(-1) \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "    print(_find_spark_home()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge scitime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import wget\n",
    "\n",
    "# Install Java, Spark, and Findspark\n",
    "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "#!python -m wget https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
    "#!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
    "#!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Program Files/Java/jdk-20\"\n",
    "#os.environ[\"SPARK_HOME\"] = \"C:/Users/bjros/Anaconda3/Lib/site-packages/pyspark\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init(r\"C:\\Users\\bjros\\Anaconda3\\Lib\\site-packages\\pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HADOOP_HOME\"] = \"C:/Users/bjros/OneDrive/Desktop/hadoop-3.3.5-src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found method to increase Heap Size at https://stackoverflow.com/questions/32336915/pyspark-java-lang-outofmemoryerror-java-heap-space\n",
    "spark = SparkSession.builder.appName(\"NaiveBayes\").config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.maxResultSize\", \"0\").config(\"spark.executor.heartbeatInterval\", \"300s\").config(\"spark.network.timeout\", \"600s\").config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found Method to Speed Up Converting Python Objects to DataFrames at spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark version= 3.3.2\n"
     ]
    }
   ],
   "source": [
    "#Check Spark Version\n",
    "print( \"spark version=\" ,SparkSession.builder.appName(\"test\").getOrCreate().version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+--------------------+----------------+\n",
      "|_c0|         product|           narrative|narrative_length|\n",
      "+---+----------------+--------------------+----------------+\n",
      "|  0|     credit_card|purchase order da...|            1705|\n",
      "|  1|     credit_card|forwarded message...|             904|\n",
      "|  2|  retail_banking|forwarded message...|            1230|\n",
      "|  3|credit_reporting|payment history m...|             903|\n",
      "|  4|credit_reporting|payment history m...|             851|\n",
      "|  5|credit_reporting|payment history m...|             849|\n",
      "|  6|credit_reporting|va date complaint...|            1395|\n",
      "|  7|credit_reporting|account reported ...|            2114|\n",
      "|  8|credit_reporting|account reported ...|            2120|\n",
      "|  9|credit_reporting|usdoexxxx account...|            2093|\n",
      "+---+----------------+--------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the Data from the CSV Files\n",
    "#complaints_df = pd.read_csv('train.csv')\n",
    "#complaints_df['narrative_length'] = train_df['narrative'].str.len()\n",
    "\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "complaints_df_with_nulls = spark.read.csv('complaints_processed.csv', sep=\",\", header=True)\n",
    "complaints_df_with_nulls = complaints_df_with_nulls.withColumn('narrative_length', length(complaints_df_with_nulls['narrative']))\n",
    "complaints_df = complaints_df_with_nulls.dropna()\n",
    "complaints_df.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tokenize the Description Columns in the DataFrames\n",
    "train_df['description_x_list'] = train_df['description_x'].apply(lambda x : word_tokenize(x))\n",
    "train_df['description_x_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['description_y_list'] = train_df['description_y'].apply(lambda x : word_tokenize(x))\n",
    "train_df['description_y_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_df['description_x_list'] = test_df['description_x'].apply(lambda x : word_tokenize(x))\n",
    "test_df['description_x_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_df['description_y_list'] = test_df['description_y'].apply(lambda x : word_tokenize(x))\n",
    "test_df['description_y_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram, HashingTF, IDF, StringIndexer\n",
    "# Create all the features to the data set\n",
    "product = StringIndexer(inputCol='product',outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"narrative\", outputCol=\"narrative_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopremove = StopWordsRemover(inputCol='narrative_tokenized',outputCol='narrative_tokenized_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Different NGram Values\n",
    "ngram = NGram(n=1, inputCol='narrative_tokenized_filtered',outputCol='narrative_ngramed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='narrative_ngramed', outputCol='narrative_hashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='narrative_hashed', outputCol='narrative_idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['narrative_idf', 'narrative_length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[product, tokenizer, stopremove, ngram, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convert Pandas DataFrames into Spark DataFrames\n",
    "#Credit to https://stackoverflow.com/questions/55604506/error-attributeerror-dataframe-object-has-no-attribute-jdf\n",
    "#from pyspark.sql import SQLContext\n",
    "\n",
    "#sqlContext = SQLContext(spark)\n",
    "\n",
    "spark_train_df = sqlContext.createDataFrame(train_df)\n",
    "spark_test_df = sqlContext.createDataFrame(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#spark_train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#spark_test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(complaints_df)\n",
    "\n",
    "cleaned = cleaner.transform(complaints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  3.0|(262145,[511,991,...|\n",
      "|  3.0|(262145,[4075,552...|\n",
      "|  4.0|(262145,[3436,538...|\n",
      "|  0.0|(262145,[6122,853...|\n",
      "|  0.0|(262145,[6122,853...|\n",
      "|  0.0|(262145,[6122,853...|\n",
      "|  0.0|(262145,[2306,688...|\n",
      "|  0.0|(262145,[2306,421...|\n",
      "|  0.0|(262145,[2306,421...|\n",
      "|  0.0|(262145,[2306,421...|\n",
      "|  2.0|(262145,[2162,407...|\n",
      "|  3.0|(262145,[651,1139...|\n",
      "|  3.0|(262145,[991,2182...|\n",
      "|  0.0|(262145,[25363,48...|\n",
      "|  1.0|(262145,[5381,612...|\n",
      "|  2.0|(262145,[1968,164...|\n",
      "|  2.0|(262145,[11395,16...|\n",
      "|  2.0|(262145,[3928,507...|\n",
      "|  2.0|(262145,[6122,113...|\n",
      "|  0.0|(262145,[4214,211...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show label and resulting features\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark[sql]\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try a Naive Bayes Model for Classification\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "complaints_df_train, complaints_df_test = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(complaints_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convert PySpark DataFrame(s) to Pandas DataFrame(s)\n",
    "cleaned_Pandas = cleaned.toPandas()\n",
    "\n",
    "#Method Found at https://sparkbyexamples.com/pyspark/pyspark-collect/\n",
    "#cleaned_X_Pandas = pd.DataFrame.from_records(cleaned_X.collect(), columns=cleaned_X.columns)\n",
    "#cleaned_Y_Pandas = pd.DataFrame.from_records(cleaned_Y.collect(), columns=cleaned_Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Try a Logistic Regression Model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Break data down into a training set and a testing set\n",
    "train_df_train_X, train_df_test_X = cleaned_X.randomSplit([0.7, 0.3])\n",
    "train_df_train_Y, train_df_test_Y = cleaned_Y.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Logistic Regression model and fit training data\n",
    "lr = LogisticRegression()\n",
    "predictor_X = lr.fit(train_df_train_X)\n",
    "predictor_Y = lr.fit(train_df_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Try a Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dividing X, y into train and test data\n",
    "complaints_df_train_features, complaints_df_test_features, complaints_df_train_labels, complaints_df_test_labels = train_test_split(cleaned_Pandas['features'], cleaned_Pandas['label'], random_state = 42)                                                                                                                                      \n",
    "  \n",
    "\n",
    "  \n",
    "# creating a confusion matrix\n",
    "#cm_X = confusion_matrix(train_df_test_X_labels, dtree_predictions_X)\n",
    "#cm_Y = confusion_matrix(train_df_test_Y_labels, dtree_predictions_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create the Models\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --install-option='--prefix=C:\\Users\\bjros\\Anaconda3\\Lib\\site-packages' scitime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install -c conda-forge scitime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check to See how long the Model Would Take to Fit\n",
    "import time\n",
    "\n",
    "from scitime import RuntimeEstimator\n",
    "estimator = RuntimeEstimator(meta_algo='RF', verbose=3)\n",
    "\n",
    "estimation, lower_bound, upper_bound = estimator.time(dtree_model, list(complaints_df_train_features))\n",
    "print(f\"The time estimation for fitting dtree_model is: {estimation}. The lower bound is: {lower_bound}. The upper bound is: {upper_bound}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training a DescisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model_trained = dtree_model.fit(list(complaints_df_train_features), complaints_df_train_labels)\n",
    "\n",
    "dtree_predictions = dtree_model.predict(list(complaints_df_test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Naive Bayes model with Bernoulli Model Type and fit training data\n",
    "nb_gaussian = NaiveBayes(modelType='gaussian')\n",
    "predictor_X_gaussian = nb_gaussian.fit(train_df_train_X)\n",
    "predictor_Y_gaussian = nb_gaussian.fit(train_df_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+----------------+-----+--------------------+----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  _c0|            product|           narrative|narrative_length|label| narrative_tokenized|narrative_tokenized_filtered|   narrative_ngramed|    narrative_hashed|       narrative_idf|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+-------------------+--------------------+----------------+-----+--------------------+----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  100|    debt_collection|wakefield associa...|             588|  1.0|[wakefield, assoc...|        [wakefield, assoc...|[wakefield, assoc...|(262144,[5078,612...|(262144,[5078,612...|(262145,[5078,612...|[-2762.6973737426...|[1.88097507847901...|       1.0|\n",
      "|10001|   credit_reporting|called creditor d...|              82|  0.0|[called, creditor...|        [called, creditor...|[called, creditor...|(262144,[13828,60...|(262144,[13828,60...|(262145,[13828,60...|[-157.23160180017...|[0.99990816028006...|       0.0|\n",
      "|10008|   credit_reporting|called equifax ap...|            1381|  0.0|[called, equifax,...|        [called, equifax,...|[called, equifax,...|(262144,[810,2437...|(262144,[810,2437...|(262145,[810,2437...|[-6004.0312132829...|[1.0,1.0232664452...|       0.0|\n",
      "| 1001|mortgages_and_loans|pmi removal conce...|              93|  2.0|[pmi, removal, co...|        [pmi, removal, co...|[pmi, removal, co...|(262144,[43756,71...|(262144,[43756,71...|(262145,[43756,71...|[-651.86620377143...|[8.09996093175374...|       2.0|\n",
      "|10010|   credit_reporting|called equifax sp...|              87|  0.0|[called, equifax,...|        [called, equifax,...|[called, equifax,...|(262144,[31536,50...|(262144,[31536,50...|(262145,[31536,50...|[-318.99009088764...|[0.99999999989822...|       0.0|\n",
      "+-----+-------------------+--------------------+----------------+-----+--------------------+----------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(complaints_df_test)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform the Bernoulli Type model with the testing data\n",
    "test_results_X_gaussian = predictor_X_gaussian.transform(train_df_test_X)\n",
    "test_results_X_gaussian.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_results_Y_gaussian = predictor_Y_gaussian.transform(train_df_test_Y)\n",
    "test_results_Y_gaussian.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting product class values was: 0.814481\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Test Accuracy of Base Model\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting product class values was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy of Model with Gaussian Type\n",
    "acc_eval_gaussian = MulticlassClassificationEvaluator()\n",
    "acc_X_gaussian = acc_eval_gaussian.evaluate(test_results_X)\n",
    "print(\"Accuracy of Gaussian Type model at predicting Ticker_X values was: %f\" % acc_X_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc_eval_gaussian = MulticlassClassificationEvaluator()\n",
    "acc_Y_gaussian = acc_eval_gaussian.evaluate(test_results_Y)\n",
    "print(\"Accuracy of Gaussian Type model at predicting Ticker_Y values was: %f\" % acc_Y_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Classification Report to Evaluate the Accuracy of the Decision Tree Model Predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f'The results of the Decision Tree model in predicting tickers is: {classification_report(complaints_df_test_labels, dtree_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://localhost:4040/api/v1/applications/[base-app-id]/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+----------+-----------------------+------------+--------------------------+-----------------------------------+------------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  _c0|            product|           narrative|prediction|narrative_length_as_str|label_as_str|narrative_tokenized_as_str|narrative_tokenized_filtered_as_str|narrative_ngramed_as_str|narrative_hashed_as_str|narrative_idf_as_str|     features_as_str|rawPrediction_as_str|  probability_as_str|\n",
      "+-----+-------------------+--------------------+----------+-----------------------+------------+--------------------------+-----------------------------------+------------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  100|    debt_collection|wakefield associa...|       1.0|                    588|         1.0|      [wakefield,associ...|               [wakefield,associ...|    [wakefield,associ...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-2762.6973737426...|[1.88097507847901...|\n",
      "|10001|   credit_reporting|called creditor d...|       0.0|                     82|         0.0|      [called,creditor,...|               [called,creditor,...|    [called,creditor,...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-157.23160180017...|[0.99990816028006...|\n",
      "|10008|   credit_reporting|called equifax ap...|       0.0|                   1381|         0.0|      [called,equifax,a...|               [called,equifax,a...|    [called,equifax,a...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-6004.0312132829...|[1.0,1.0232664452...|\n",
      "| 1001|mortgages_and_loans|pmi removal conce...|       2.0|                     93|         2.0|      [pmi,removal,conc...|               [pmi,removal,conc...|    [pmi,removal,conc...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-651.86620377143...|[8.09996093175374...|\n",
      "|10010|   credit_reporting|called equifax sp...|       0.0|                     87|         0.0|      [called,equifax,s...|               [called,equifax,s...|    [called,equifax,s...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-318.99009088764...|[0.99999999989822...|\n",
      "|10018|    debt_collection|called announced ...|       1.0|                    411|         1.0|      [called,announced...|               [called,announced...|    [called,announced...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-2224.0099870590...|[1.12234419289300...|\n",
      "|10019|    debt_collection|called told someo...|       1.0|                    366|         1.0|      [called,told,some...|               [called,told,some...|    [called,told,some...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1482.7966192928...|[1.75668695183448...|\n",
      "|10020|mortgages_and_loans|called great lake...|       2.0|                    446|         2.0|      [called,great,lak...|               [called,great,lak...|    [called,great,lak...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-2979.5231207283...|[1.23129909021207...|\n",
      "|10022|mortgages_and_loans|called homepoimtn...|       2.0|                    292|         2.0|      [called,homepoimt...|               [called,homepoimt...|    [called,homepoimt...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1324.0233370723...|[2.00448787175629...|\n",
      "|10025|mortgages_and_loans|called u bank wai...|       2.0|                    306|         2.0|      [called,u,bank,wa...|               [called,u,bank,wa...|    [called,u,bank,wa...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1567.9120901555...|[7.30028692431664...|\n",
      "|10027|        credit_card|called kohl custo...|       3.0|                    273|         3.0|      [called,kohl,cust...|               [called,kohl,cust...|    [called,kohl,cust...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1721.5581027522...|[3.77503704917887...|\n",
      "|10031|mortgages_and_loans|called mr cooper ...|       2.0|                    472|         2.0|      [called,mr,cooper...|               [called,mr,cooper...|    [called,mr,cooper...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-2095.6576923930...|[1.14647798089050...|\n",
      "|10034|        credit_card|called credit car...|       3.0|                    382|         3.0|      [called,credit,ca...|               [called,credit,ca...|    [called,credit,ca...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1690.0528409905...|[2.79379290417330...|\n",
      "|10036|    debt_collection|called phone repe...|       1.0|                    158|         1.0|      [called,phone,rep...|               [called,phone,rep...|    [called,phone,rep...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-851.68640033745...|[8.88536278037656...|\n",
      "|10037|mortgages_and_loans|called national c...|       1.0|                    283|         2.0|      [called,national,...|               [called,national,...|    [called,national,...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1460.0458234709...|[3.00590318144143...|\n",
      "|10042|     retail_banking|called see deposi...|       4.0|                    133|         4.0|      [called,see,depos...|               [called,see,depos...|    [called,see,depos...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-710.04007932635...|[3.12526412179148...|\n",
      "|10044|mortgages_and_loans|called pennymac s...|       2.0|                    504|         2.0|      [called,pennymac,...|               [called,pennymac,...|    [called,pennymac,...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-2258.1756292821...|[2.20907945571029...|\n",
      "|10052|mortgages_and_loans|called sl numerou...|       2.0|                   1163|         2.0|      [called,sl,numero...|               [called,sl,numero...|    [called,sl,numero...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-6834.5122034563...|[6.87145582522815...|\n",
      "| 1006|mortgages_and_loans|quicken loan bega...|       2.0|                    234|         2.0|      [quicken,loan,beg...|               [quicken,loan,beg...|    [quicken,loan,beg...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-1003.5451797071...|[3.34003955934974...|\n",
      "|10061|    debt_collection|called collector ...|       1.0|                    164|         1.0|      [called,collector...|               [called,collector...|    [called,collector...|   [0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|[-562.86197472600...|[0.00077830905011...|\n",
      "+-----+-------------------+--------------------+----------+-----------------------+------------+--------------------------+-----------------------------------+------------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Write to CSV File\n",
    "#Found Method to Concetanate Strings in PySpark with https://stackoverflow.com/questions/40426106/spark-2-0-x-dump-a-csv-file-from-a-dataframe-containing-one-array-of-type-string\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def array_to_string(my_list):\n",
    "    return '[' + ','.join([str(elem) for elem in my_list]) + ']'\n",
    "\n",
    "array_to_string_udf = udf(array_to_string, StringType())\n",
    "\n",
    "test_results_1 = test_results.withColumn('narrative_length_as_str', test_results[\"narrative_length\"].cast(\"string\")) \\\n",
    "    .withColumn('label_as_str', test_results[\"label\"].cast(\"string\")) \\\n",
    "    .withColumn('narrative_tokenized_as_str', array_to_string_udf(test_results[\"narrative_tokenized\"])) \\\n",
    "    .withColumn('narrative_tokenized_filtered_as_str', array_to_string_udf(test_results[\"narrative_tokenized_filtered\"])) \\\n",
    "    .withColumn('narrative_ngramed_as_str', array_to_string_udf(test_results[\"narrative_ngramed\"])) \\\n",
    "    .withColumn('narrative_hashed_as_str', array_to_string_udf(test_results[\"narrative_hashed\"])) \\\n",
    "    .withColumn('narrative_idf_as_str', array_to_string_udf(test_results[\"narrative_idf\"])) \\\n",
    "    .withColumn('features_as_str', array_to_string_udf(test_results[\"features\"])) \\\n",
    "    .withColumn('rawPrediction_as_str', array_to_string_udf(test_results[\"rawPrediction\"])) \\\n",
    "    .withColumn('probability_as_str', array_to_string_udf(test_results[\"probability\"]))\n",
    "\n",
    "test_results_2 = test_results_1.drop(\"narrative_length\") \\\n",
    "    .drop(\"label\") \\\n",
    "    .drop(\"narrative_tokenized\") \\\n",
    "    .drop(\"narrative_tokenized_filtered\") \\\n",
    "    .drop(\"narrative_ngramed\") \\\n",
    "    .drop(\"narrative_hashed\") \\\n",
    "    .drop(\"narrative_idf\") \\\n",
    "    .drop(\"features\") \\\n",
    "    .drop(\"rawPrediction\") \\\n",
    "    .drop(\"probability\")\n",
    "\n",
    "test_results_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set Socket Wait Time\n",
    "import socket\n",
    "socket.setdefaulttimeout(10)\n",
    "sock = socket.socket()\n",
    "sock.settimeout(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to a CSV File\n",
    "#test_results_2.select([\"_c0\", \"product\", \"narrative\"]).write.csv('C:/Users/bjros/OneDrive/Desktop/Kaggle Data Sets/Consumer_Complaints/complaints_with_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Results to a File\n",
    "#test_results_2.write.csv('C:/Users/bjros/OneDrive/Desktop/Kaggle Data Sets/Consumer_Complaints/complaints_with_predictions.csv')\n",
    "test_results_2.select([\"_c0\", \"product\", \"narrative\", \"label_as_str\", \"prediction\"]).toPandas().to_csv('C:/Users/bjros/OneDrive/Desktop/Kaggle Data Sets/Consumer_Complaints/complaints_with_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results\n",
    "#Multi-class Classification Evaluator\n",
    "#N Grams = 1\n",
    "#acc = [0.810295, 0.811987, 0.812360]\n",
    "#acc_gaussian = \n",
    "\n",
    "#N Grams = 2\n",
    "#acc = [0.797944, 0.800598, 0.797773]\n",
    "#acc_gaussian = \n",
    "\n",
    "\n",
    "#N Grams = 3\n",
    "#acc = [0.619139, 0.615107, 0.615909]\n",
    "#acc_gaussian = \n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "#acc_X =\n",
    "#acc_Y = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
